{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Gebby Novalisza </br>\n",
        "NIM : 1102201399 </br>\n",
        "Kelas : EL-43-D"
      ],
      "metadata": {
        "id": "4xCokhgSoqFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjRwqI0NmvwR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "with gzip.open('/content/movie_data.csv.gz', 'rb') as f_in, open('/content/movie_data.csv', 'wb') as f_out:\n",
        "  shutil.copyfileobj(f_in, f_out)\n"
      ],
      "metadata": {
        "id": "eeV3zIllpBcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/movie_data.csv')\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0ffeHbEvpbJB",
        "outputId": "28793b7f-594d-4577-a884-3ad5aea62748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment\n",
              "49995  OK, lets start with the best. the building. al...          0\n",
              "49996  The British 'heritage film' industry is out of...          0\n",
              "49997  I don't even know where to begin on this one. ...          0\n",
              "49998  Richard Tyler is a little boy who is scared of...          0\n",
              "49999  I waited long to watch this movie. Also becaus...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1ae0932-9cb0-475a-aa5e-559c50c7b340\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>OK, lets start with the best. the building. al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>The British 'heritage film' industry is out of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I don't even know where to begin on this one. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>I waited long to watch this movie. Also becaus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1ae0932-9cb0-475a-aa5e-559c50c7b340')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1ae0932-9cb0-475a-aa5e-559c50c7b340 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1ae0932-9cb0-475a-aa5e-559c50c7b340');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a dataset\n",
        "\n",
        "target = df.pop('sentiment')\n",
        "ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        " (df.values, target.values))\n",
        "\n",
        "## inspection:\n",
        "for ex in ds_raw.take(3):\n",
        " tf.print(ex[0].numpy()[0][:50], ex[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUkiPRWGuuiJ",
        "outputId": "1f13fb97-dada-4d2a-9061-f5cab5ff5e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
            "b'OK... so... I really like Kris Kristofferson and h' 0\n",
            "b'***SPOILER*** Do not read this, if you think about' 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Buat objek dataser TensorFlow dan pisahkan menjadi partisi training, testing, dan validasi set yang terpisah.\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds_raw = ds_raw.shuffle(\n",
        " 50000, reshuffle_each_iteration=False)\n",
        "\n",
        "ds_raw_test = ds_raw.take(25000)\n",
        "ds_raw_train_valid = ds_raw.skip(25000)\n",
        "ds_raw_train = ds_raw_train_valid.take(20000)\n",
        "ds_raw_valid = ds_raw_train_valid.skip(20000)"
      ],
      "metadata": {
        "id": "T8Ptyh1iu6Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: Identifikasi kata-kata unik dalam dataset training.\n",
        "from collections import Counter\n",
        "try:\n",
        " tokenizer = tfds.features.text.Tokenizer()\n",
        "except AttributeError:\n",
        " tokenizer = tfds.deprecated.text.Tokenizer()\n",
        " \n",
        "token_counts = Counter()\n",
        "for example in ds_raw_train:\n",
        " tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        " token_counts.update(tokens)\n",
        " \n",
        "print('Vocab-size:', len(token_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODdPxpkvMgV",
        "outputId": "b82d52de-010f-4736-d6fb-51d6403805cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 87063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: encoding each unique token into integers\n",
        "try:\n",
        " encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
        "except AttributeError:\n",
        " encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
        "example_str = 'This is an example!'\n",
        "encoder.encode(example_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9W-MAffvmQQ",
        "outputId": "6b5d3d65-8445-4273-9984-b5dc78ab2e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[544, 40, 223, 2166]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3-A: define the function for transformation\n",
        "def encode(text_tensor, label):\n",
        " text = text_tensor.numpy()[0]\n",
        " encoded_text = encoder.encode(text)\n",
        " return encoded_text, label\n",
        "\n",
        "## Step 3-B: wrap the encode function to a TF Op.\n",
        "def encode_map_fn(text, label):\n",
        " return tf.py_function(encode, inp=[text, label],\n",
        " Tout=(tf.int64, tf.int64))"
      ],
      "metadata": {
        "id": "YNSsC_Vnv3hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_raw_train.map(encode_map_fn)\n",
        "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "ds_test = ds_raw_test.map(encode_map_fn)\n",
        "tf.random.set_seed(1)\n",
        "for example in ds_train.shuffle(1000).take(5):\n",
        " print('Sequence length:', example[0].shape)\n",
        " \n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klEVQ9iPv8Gn",
        "outputId": "81424359-c6c8-4cfc-c5c3-38dab847ddcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence length: (109,)\n",
            "Sequence length: (177,)\n",
            "Sequence length: (281,)\n",
            "Sequence length: (199,)\n",
            "Sequence length: (124,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(124,), dtype=int64, numpy=\n",
              " array([   86,  9018, 12346, 16862,    40,    46,   653,  3385,     8,\n",
              "           46,    22,    71,   181,    33, 16863,   513,    17,     9,\n",
              "         3032,  2844,     8,   401, 16864, 15670,  4170,   319,   319,\n",
              "          337,   299,    51,    86,   837,    40, 16224, 16865, 16866,\n",
              "         2871,    44,   270,  1719,    14, 11589, 10498,   116,  1072,\n",
              "         1106,   223,   313,  4994,  2488,    16,    30,   483,    58,\n",
              "          268,   183,   604,   105,     9,  1842,  8139,  4170,   219,\n",
              "          299,   223,  2246,   545,   515,   972,   249,    46, 16867,\n",
              "           46,  3622,  3974,  9073,  4405,    46,  3032,  3142,   972,\n",
              "           14,    46,  6036,    44,     9, 16868,  2046,    14,    61,\n",
              "          299,    46,  8701,  1029,   139,    46,  3275,    14,    46,\n",
              "        16869,   214,  4891,   319,   319,   263,  2537,   299,  1183,\n",
              "          374,  4104,  3797,  8139,  4170,   299, 16870,  8519,    14,\n",
              "           13,   125,    44,   284,  4422, 13384,  1207])>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Take a small subset\n",
        "ds_subset = ds_train.take(8)\n",
        "for example in ds_subset:\n",
        " print('Individual size:', example[0].shape)\n",
        "\n",
        "## batching the datasets\n",
        "ds_batched = ds_subset.padded_batch(\n",
        " 4, padded_shapes=([-1], []))\n",
        "\n",
        "for batch in ds_batched:\n",
        " print('Batch dimension:', batch[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULQhp3BMwEZ8",
        "outputId": "668143ab-3c99-4588-938b-ac2a53bcfe3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual size: (236,)\n",
            "Individual size: (250,)\n",
            "Individual size: (193,)\n",
            "Individual size: (310,)\n",
            "Individual size: (143,)\n",
            "Individual size: (258,)\n",
            "Individual size: (214,)\n",
            "Individual size: (117,)\n",
            "Batch dimension: (4, 310)\n",
            "Batch dimension: (4, 258)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## batching the datasets\n",
        "train_data = ds_train.padded_batch(\n",
        " 32, padded_shapes=([-1],[]))\n",
        "\n",
        "valid_data = ds_valid.padded_batch(\n",
        " 32, padded_shapes=([-1],[]))\n",
        "\n",
        "test_data = ds_test.padded_batch(\n",
        " 32, padded_shapes=([-1],[]))\n"
      ],
      "metadata": {
        "id": "Fl07aaUuwQkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding Layers untuk Sentence Encoding**"
      ],
      "metadata": {
        "id": "a58zl8LqwTmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(input_dim=100,\n",
        "                    output_dim=6,\n",
        "                    input_length=20,\n",
        "                    name='embed-layer'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bVo7smkwXNB",
        "outputId": "91d9697f-fc82-4b96-b35b-3a86666bae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, 20, 6)             600       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600\n",
            "Trainable params: 600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membangun RNN Model**"
      ],
      "metadata": {
        "id": "dTYuj-_bwmk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ucl5xqJwkdN",
        "outputId": "a7b881b7-5330-4714-d552-999a9df82afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          32000     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 32)          2080      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,193\n",
            "Trainable params: 36,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membangun RNN Model untuk Tugas Sentiment Analysis**"
      ],
      "metadata": {
        "id": "Uu9T49TPwrh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LsauNn5wzVx",
        "outputId": "f221b084-852a-41cb-a02c-612f27bcb296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 32)          320000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 32)          8320      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336,673\n",
            "Trainable params: 336,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 20\n",
        "vocab_size = len(token_counts) + 100000\n",
        "tf.random.set_seed(1)\n",
        "## build the model\n",
        "bi_lstm_model = tf.keras.Sequential([\n",
        " tf.keras.layers.Embedding(\n",
        "    input_dim=vocab_size+100000,\n",
        "    output_dim=embedding_dim,\n",
        "    name='embed-layer'),\n",
        " \n",
        " tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(64, name='lstm-layer'),\n",
        "    name='bidir-lstm'),\n",
        " tf.keras.layers.Dense(64, activation='relu'),\n",
        " \n",
        " tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "bi_lstm_model.summary()\n",
        "\n",
        "## compile and train:\n",
        "\n",
        "bi_lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = bi_lstm_model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=2)\n",
        "\n",
        "## evaluate on the test data\n",
        "test_results= bi_lstm_model.evaluate(test_data)\n",
        "print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FXrZTYVxEAQ",
        "outputId": "cfcbf7e1-2394-4b9c-fe8d-d6d82776a5c2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, None, 20)          5741260   \n",
            "                                                                 \n",
            " bidir-lstm (Bidirectional)  (None, 128)               43520     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,793,101\n",
            "Trainable params: 5,793,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "625/625 [==============================] - 716s 1s/step - loss: 0.5018 - accuracy: 0.7524 - val_loss: 0.3740 - val_accuracy: 0.8548\n",
            "Epoch 2/2\n",
            "625/625 [==============================] - 708s 1s/step - loss: 0.3376 - accuracy: 0.8647 - val_loss: 0.3885 - val_accuracy: 0.8410\n",
            "782/782 [==============================] - 175s 223ms/step - loss: 0.4065 - accuracy: 0.8371\n",
            "Test Acc.: 83.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_datasets(\n",
        " ds_raw_train,\n",
        " ds_raw_valid,\n",
        " ds_raw_test,\n",
        " max_seq_length=None,\n",
        " batch_size=32):\n",
        " \n",
        " ## Step 1: (already done => creating a dataset)\n",
        " ## Step 2: find unique tokens\n",
        "\n",
        "  try:\n",
        "    tokenizer = tfds.features.text.Tokenizer()\n",
        "  except AttributeError:\n",
        "    tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "  token_counts = Counter()\n",
        "\n",
        "  for example in ds_raw_train:\n",
        "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        "    if max_seq_length is not None:\n",
        "      tokens = tokens[-max_seq_length:]\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "  print('Vocab-size:', len(token_counts))\n",
        "\n",
        "  ## Step 3: encoding the texts\n",
        "  try:\n",
        "    encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
        "  except AttributeError:\n",
        "    encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
        "  def encode(text_tensor, label):\n",
        "    text = text_tensor.numpy()[0]\n",
        "    encoded_text = encoder.encode(text)\n",
        "    if max_seq_length is not None:\n",
        "      encoded_text = encoded_text[-max_seq_length:]\n",
        "    return encoded_text, label\n",
        "\n",
        "    def encode_map_fn(text, label):\n",
        "      return tf.py_function(encode, inp=[text, label],\n",
        "                            Tout=(tf.int64, tf.int64))\n",
        "    ds_train = ds_raw_train.map(encode_map_fn)\n",
        "    ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "    ds_test = ds_raw_test.map(encode_map_fn)\n",
        "\n",
        "  ## Step 4: batching the datasets\n",
        "  train_data = ds_train.padded_batch(\n",
        "      batch_size, padded_shapes=([-1],[]))\n",
        "  \n",
        "  valid_data = ds_valid.padded_batch(\n",
        "      batch_size, padded_shapes=([-1],[]))\n",
        "  \n",
        "  test_data = ds_test.padded_batch(\n",
        "      batch_size, padded_shapes=([-1],[]))\n",
        "  \n",
        "  return (train_data, valid_data,\n",
        "          test_data, len(token_counts))"
      ],
      "metadata": {
        "id": "cw5f5JVIxf9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rnn_model(embedding_dim, vocab_size,\n",
        "                    recurrent_type='SimpleRNN',\n",
        "                    n_recurrent_units=64,\n",
        "                    n_recurrent_layers=1,\n",
        "                    bidirectional=True):\n",
        "  \n",
        "  tf.random.set_seed(1)\n",
        "  \n",
        "  # build the model\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  model.add(\n",
        "      Embedding(\n",
        "          input_dim=vocab_size,\n",
        "          output_dim=embedding_dim,\n",
        "          name='embed-layer')\n",
        "  )\n",
        " \n",
        "  for i in range(n_recurrent_layers):\n",
        "    return_sequences = (i < n_recurrent_layers-1)\n",
        "\n",
        "    if recurrent_type == 'SimpleRNN':\n",
        "      recurrent_layer = SimpleRNN(\n",
        "          units=n_recurrent_units,\n",
        "          return_sequences=return_sequences,\n",
        "          name='simprnn-layer-{}'.format(i))\n",
        "\n",
        "    elif recurrent_type == 'LSTM':\n",
        "      recurrent_layer = LSTM(\n",
        "          units=n_recurrent_units,\n",
        "          return_sequences=return_sequences,\n",
        "          name='lstm-layer-{}'.format(i))\n",
        "    \n",
        "    elif recurrent_type == 'GRU':\n",
        "      recurrent_layer = GRU(\n",
        "          units=n_recurrent_units,\n",
        "          return_sequences=return_sequences,\n",
        "          name='gru-layer-{}'.format(i))\n",
        "\n",
        "    if bidirectional:\n",
        "      recurrent_layer = Bidirectional(\n",
        "          recurrent_layer, name='bidir-'+recurrent_layer.name)\n",
        "\n",
        "  model.add(recurrent_layer)\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "3_yBBe4Eypkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "batch_size = 32\n",
        "embedding_dim = 20\n",
        "max_seq_length = 100\n",
        "\n",
        "train_data, valid_data, test_data, n = preprocess_datasets(\n",
        "    ds_raw_train, ds_raw_valid, ds_raw_test,\n",
        "    max_seq_length=max_seq_length,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "vocab_size = n + 100000\n",
        "\n",
        "rnn_model = build_rnn_model(\n",
        "    embedding_dim, vocab_size,\n",
        "    recurrent_type='SimpleRNN',\n",
        "    n_recurrent_units=64,\n",
        "    n_recurrent_layers=1,\n",
        "    bidirectional=True)\n",
        "\n",
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjcl7I5-0QQI",
        "outputId": "4f24566f-1e0e-4362-efd6-526afee4c902"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 58112\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, None, 20)          3162240   \n",
            "                                                                 \n",
            " bidir-simprnn-layer-0 (Bidi  (None, 128)              10880     \n",
            " rectional)                                                      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,181,441\n",
            "Trainable params: 3,181,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history = rnn_model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GINIkp_60o1a",
        "outputId": "e600344a-9a41-40a0-b49a-be2fd6444178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "625/625 [==============================] - 348s 553ms/step - loss: 0.7003 - accuracy: 0.5125 - val_loss: 0.6989 - val_accuracy: 0.5202\n",
            "Epoch 2/2\n",
            "625/625 [==============================] - 349s 558ms/step - loss: 0.5983 - accuracy: 0.6727 - val_loss: 0.4999 - val_accuracy: 0.7884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = rnn_model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6g1Cf200xX4",
        "outputId": "30426f32-b46a-4bcf-ae0b-5419add3bf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 78s 99ms/step - loss: 0.5229 - accuracy: 0.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Acc.: {:.2f}%'.format(results[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv1dcjIL1Efi",
        "outputId": "f8ffa7f4-a344-4d05-e733-8f93294a91e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc.: 77.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size1 = vocab_size + 100000\n",
        "\n",
        "lstm_model = build_rnn_model(\n",
        "    embedding_dim, vocab_size1,\n",
        "    recurrent_type='LSTM',\n",
        "    n_recurrent_units=64,\n",
        "    n_recurrent_layers=1,\n",
        "    bidirectional=True)\n",
        "\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAo0Z4Q11INP",
        "outputId": "f9ed9476-72c6-4521-e17d-a5786b9031b7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, None, 20)          5162240   \n",
            "                                                                 \n",
            " bidir-lstm-layer-0 (Bidirec  (None, 128)              43520     \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,214,081\n",
            "Trainable params: 5,214,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                   loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "history = lstm_model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4pToKWT1Oxk",
        "outputId": "5839ef13-21ae-4d17-afdb-6713ca2843fc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "625/625 [==============================] - 689s 1s/step - loss: 0.5013 - accuracy: 0.7491 - val_loss: 0.3560 - val_accuracy: 0.8490\n",
            "Epoch 2/2\n",
            "625/625 [==============================] - 685s 1s/step - loss: 0.2374 - accuracy: 0.9113 - val_loss: 0.3373 - val_accuracy: 0.8650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_lstm = lstm_model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Vewhqn1y1eRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e3a80a-400c-4d79-b61c-aa7e7c1fe9b1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 171s 218ms/step - loss: 0.3498 - accuracy: 0.8627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Acc.: {:.2f}%'.format(results_lstm[1]*100))"
      ],
      "metadata": {
        "id": "xtp6jj-K1is2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98eb2828-f6b6-4a68-a452-0521222951d3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc.: 86.27%\n"
          ]
        }
      ]
    }
  ]
}